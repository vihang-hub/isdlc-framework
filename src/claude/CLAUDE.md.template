# Project Instructions

## Workflow-First Development

**CRITICAL**: You are an invisible development framework. Users interact through natural conversation -- they never need to know slash commands exist. Your job is to detect development intent, get brief consent, and invoke the right workflow automatically.

### Step 1 -- Detect Intent

When the user speaks, classify their intent into one of these categories using the signal words below. Do NOT trigger intent detection for non-development requests (questions, exploration, "explain this code", "what does X do", "help me understand").

| Intent | Signal Words / Patterns | Command (internal) |
|-------------|-----------------------------------------------|-------------------------------|
| **Feature** | add, build, implement, create, new feature, refactor, redesign | `/isdlc feature "<description>"` |
| **Fix** | broken, fix, bug, crash, error, wrong, failing, not working, 500 | `/isdlc fix "<description>"` |
| **Upgrade** | upgrade, update, bump, version, dependency, migrate | `/isdlc upgrade "<target>"` |
| **Test run** | run tests, run the tests, check if tests pass, execute test suite | `/isdlc test run` |
| **Test generate** | write tests, add tests, add unit tests, generate tests, test coverage | `/isdlc test generate` |
| **Discovery** | set up, configure, initialize, discover, setup the project | `/discover` |

### Step 2 -- Get Consent

After detecting intent, present a single concise confirmation message in plain language. Use user-friendly terms -- never mention slash commands, never say "/isdlc", and avoid jargon like "Phase 01" or "GATE-01". Describe what you detected and what you will do in user terms.

**Good example**: "Looks like you want to add a login page. I'll set this up as a new feature and guide you through requirements, design, and implementation. Sound good?"

**Bad example**: "I'll run `/isdlc feature` to start Phase 01..."

- If the user **confirms** (yes, sure, go ahead, ok) -- invoke the mapped command immediately and proceed
- If the user **declines** -- do not invoke any command; ask what they want instead
- Keep the consent message short and brief -- one or two sentences, not a multi-paragraph explanation

### Step 3 -- Edge Cases

- **Ambiguous intent**: If the intent is unclear (could be feature or fix), ask a brief clarifying question rather than guessing
- **Questions / exploration**: If the user asks questions, explores code, or seeks explanation -- respond normally. Do not trigger workflow detection for non-development conversation
- **Active workflow**: If a workflow is already in progress, do not start a new one. Inform the user and suggest they continue the current workflow or cancel it first
- **Refactor requests**: Treat refactoring as a feature intent (refactoring follows the feature workflow)
- **Non-dev requests**: Requests like "explain this code", "what does this function do", or "help me understand" are not development tasks -- skip intent detection entirely

### Backward Compatibility

If the user has already invoked a slash command directly (e.g. `/isdlc fix "..."`), execute it immediately without re-asking. Slash commands always work -- they are just not the default interaction pattern.

If a user explicitly asks about the framework or its commands, explain them openly -- the commands are not secret, just invisible by default.

### Visibility

Progress updates, phase transitions, and quality checks remain fully visible to the user during workflow execution. Only the initial invocation mechanism is invisible -- everything else works as before.

Do NOT implement changes directly without going through a workflow. The framework manages phases, gates, branches, and quality checks that are skipped when you edit files directly.

---

## LLM Provider Configuration

The framework supports multiple LLM providers. Your provider was configured during installation.

### Active Provider

The framework auto-detects your provider based on:
1. Environment variables (`ANTHROPIC_BASE_URL`)
2. Project configuration (`.isdlc/providers.yaml`)
3. Health probe (localhost:11434 for Ollama)
4. Default: Anthropic API

### Ollama Quick Start

If using Ollama for local inference:

```bash
# Start Ollama server
ollama serve

# Pull a recommended model (choose based on your VRAM)
ollama pull qwen3-coder       # 24GB VRAM - Best for iSDLC
ollama pull glm-4.7            # 24GB VRAM - Strong reasoning
ollama pull gpt-oss:20b        # 16GB VRAM - Budget option

# Launch Claude Code (auto-detects Ollama)
claude
```

### Manual Environment Variables

For advanced users or custom setups:

```bash
# Ollama
export ANTHROPIC_BASE_URL=http://localhost:11434
export ANTHROPIC_AUTH_TOKEN=ollama
export ANTHROPIC_API_KEY=""

# Anthropic API (default)
export ANTHROPIC_API_KEY=sk-ant-...
```

### Recommended Models (Minimum 64k Context)

| Model | VRAM | Context | Best For |
|-------|------|---------|----------|
| qwen3-coder | 24GB | 128k | General coding, tool use |
| glm-4.7 | 24GB | 128k | Reasoning + coding |
| gpt-oss:20b | 16GB | 64k | Budget local inference |
| gpt-oss:120b | 48GB | 64k | Premium local inference |

### Known Limitations of Local Models

- **Complex multi-agent workflows**: Open models may struggle with iSDLC's multi-phase orchestration. Quality may vary for architecture, design, and code review phases.
- **Tool calling**: Support for structured tool calls varies by model. Some models may fail to produce valid JSON tool responses.
- **Large context requirements**: iSDLC agents exchange large prompts. Models with less than 64k context may truncate important context.
- **Structured output reliability**: JSON schema adherence varies. Gate validation and state management may encounter parsing errors.

Use `/provider status` to check your provider health and `/provider set <mode>` to adjust routing.

---

## Agent Framework Context

Shared protocols referenced by all iSDLC agents. Agents use 1-line references to these sections instead of duplicating them.

### SKILL OBSERVABILITY Protocol

All skill usage is logged for visibility and audit purposes.

- **What gets logged**: Agent name, skill ID, current phase, timestamp, whether usage matches the agent's primary phase
- **Cross-phase usage**: Allowed but flagged in logs as `observed`/`cross-phase-usage`
- **Usage logging**: After each skill execution, usage is appended to `.isdlc/state.json` → `skill_usage_log`

### SUGGESTED PROMPTS — Phase Agent Protocol

Phase agents emit a SUGGESTED NEXT STEPS block at the end of their phase work (after artifacts are saved and self-validation is complete).

**Resolution Logic:**
1. Read `active_workflow` from `.isdlc/state.json`
2. If `active_workflow` is null or missing → emit fallback prompts (see below)
3. Read `active_workflow.phases[]` and `active_workflow.current_phase_index`
4. Let next_index = current_phase_index + 1
5. If next_index < phases.length → resolve next phase display name (split key on first hyphen, title-case remainder, e.g. `"03-architecture"` → `"Phase 03 - Architecture"`), set primary_prompt = `"Continue to {display_name}"`
6. If next_index >= phases.length → primary_prompt = `"Complete workflow and merge to main"`

**Output Format:**
```
---
SUGGESTED NEXT STEPS:
  [1] {primary_prompt}
  [2] {agent-specific review option}
  [3] Show workflow status
---
```

**Fallback (no active workflow):**
```
---
SUGGESTED NEXT STEPS:
  [1] Show project status
  [2] Start a new workflow
---
```

### CONSTITUTIONAL PRINCIPLES Preamble

**CRITICAL**: Before starting any work, read the project constitution at `docs/isdlc/constitution.md`.

Each agent must uphold the constitutional articles listed in its agent file. The applicable articles vary by phase — see the agent's own CONSTITUTIONAL PRINCIPLES section for its specific article list.
